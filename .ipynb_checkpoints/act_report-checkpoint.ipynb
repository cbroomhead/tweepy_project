{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning the data, I was particularly interested in the prediction made by the neural network, which was one of the dataset retreived. \n",
    "\n",
    "To do this, I created my own dataset in 'dogbreeds.csv'. This is a .csv file that I created by copy/pasting a list of dog bread located in 'https://en.wikipedia.org/wiki/List_of_dog_breeds'. The original intent was to identify non-dogs that the model predicted, but irregularities in the 'p1' column proved to make this difficult. However, I move forward with the evaluation any. \n",
    "\n",
    "Here are the questions I sought to answer:\n",
    "\n",
    "1. How many dogs in the p1 columns are verified dogs per the data pulled in the list?\n",
    "2. Of the verified dogs per 1. above, which ones tend to be the most popular?\n",
    "3. Without any filtering, which dogs are the most predicted by the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How many dogs in the p1 columns are verified dogs per the data pulled in the list?</br>\n",
    "- After the list was merged, only 352 dogs were verified which represents about 18.6% of the entries from the master dataframe. \n",
    "\n",
    "2. Of the verified dogs per 1. above, which ones tend to be the top 5 popular?\n",
    "![title](verified_dogs.png)\n",
    "\n",
    "3. Without any filtering, which dogs are the top 5 predicted by the model?\n",
    "![title](predicted_dogs.png)\n",
    "\n",
    "\n",
    "The findings above show that the most popular verified dogs by the model were similar to the most popular verified dogs. This makes sense since the verfieid dogs represents a sample of the predicted dogs. \n",
    "\n",
    "To refine this analysis, I would try to clean up the predicted dogs p1 column to ensure less variation in the different dogs breeds. For example, and quick glnace reveals that the model used dog breeds like 'basset' when the list to check against was 'basset hounds'. this would result in a false negative, which could undermine the perceive accuracy of the model in predicted dogs and not something else (like an orange). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
